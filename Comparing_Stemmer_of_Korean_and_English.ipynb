{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Comparing Stemmer of Korean and English.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cw210HhT2gz3"
      },
      "source": [
        "# Stemming Korean and English\n",
        "\n",
        "@hyyoka"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-KgZWh5SdZe"
      },
      "source": [
        "머신러닝은 **데이터에 기반한 모델링 기법**이다. 다시 말해, 머신러닝의 하위 분야에 속하는 자연어 처리(NLP)에서 텍스트 데이터는 매우 중요하다.\n",
        "\n",
        "</br>\n",
        "\n",
        "데이터는 크게 두 가지 측면에서 평가한다: \"**양과 질**\". 모을 수 있는 데이터의 양은 한정되어 있으므로, 모델의 성능을 향상하기 위해서는 가지고 있는 데이터의 질을 높이는 작업이 이루어져야 한다. \n",
        "\n",
        "</br>\n",
        "\n",
        "본 포스트에서는 데이터의 질을 높이기 위한 정규화(Normalization)의 기법 중, **어간 추출(Stemming)**과 **표제어 추출(Lemmatization)**을 다룬다. \n",
        "\n",
        "두 기법은 모두 단어의 개수를 줄일 수 있는 방법으로, 보통 단어의 빈도수를 기반으로 하는 BoW 표현을 사용하는 자연어 처리 문제에서 사용된다. 자연어 처리에서 정규화의 지향점은 언제나 코퍼스의 복잡성을 줄이는 일이다. 위의 두 기법은 해당 목표에 기여한다. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-I0D2MZZ2cyN"
      },
      "source": [
        "## A.\n",
        "i. Find out any stemmer or lemmatizer for English on the Internet.\n",
        "\n",
        "ii. Install the system on your machine, if necessary.\n",
        "\n",
        "iii. Try stemming and lemmatization with several English words\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjEdCWzgyRVF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "c1ac177a-4bf3-4ba7-aaee-c496a7df2464"
      },
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e7pA15CztDa"
      },
      "source": [
        "# Stemmer와 Lemmatizer 비교\n",
        "\n",
        "s = PorterStemmer()\n",
        "n = WordNetLemmatizer()\n",
        "l = LancasterStemmer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRHKijjvenJ1"
      },
      "source": [
        "각각을 평가하기 위해서는, 가장 평범한 텍스트를 가져와야 한다고 생각했다. 따라서, 랜덤한 책을 골라, 첫 페이지의 첫 문단을 옮겨왔다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBSNy45kyhGi"
      },
      "source": [
        "text=\"\"\"\n",
        "There was no hope for him this time: it was the third stroke.\n",
        "Night after night I had passed the house and studied the lighted square of window: \n",
        "and night after night I had found it lighted in the same way, faintly and evenly.\n",
        "If he was dead, I thought, I would see the reflection of candles on the darkened blind for I knew that two candles must be set at the head of a corpse.\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfjGWwMyyWzY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "d10ba5f6-08cf-4673-8a93-19dc32454665"
      },
      "source": [
        "words = word_tokenize(text)\n",
        "\n",
        "stm_p = [s.stem(w) for w in words]\n",
        "stm_l = [l.stem(w) for w in words]\n",
        "lem = [n.lemmatize(w) for w in words]\n",
        "\n",
        "data = [words, stm_p, stm_l, lem]\n",
        "\n",
        "df1 = pd.DataFrame(data, index=[\"word\", \"stem_p\",\"stem_l\",\"lemma\"])\n",
        "df1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>80</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>word</th>\n",
              "      <td>There</td>\n",
              "      <td>was</td>\n",
              "      <td>no</td>\n",
              "      <td>hope</td>\n",
              "      <td>for</td>\n",
              "      <td>him</td>\n",
              "      <td>this</td>\n",
              "      <td>time</td>\n",
              "      <td>:</td>\n",
              "      <td>it</td>\n",
              "      <td>was</td>\n",
              "      <td>the</td>\n",
              "      <td>third</td>\n",
              "      <td>stroke</td>\n",
              "      <td>.</td>\n",
              "      <td>Night</td>\n",
              "      <td>after</td>\n",
              "      <td>night</td>\n",
              "      <td>I</td>\n",
              "      <td>had</td>\n",
              "      <td>passed</td>\n",
              "      <td>the</td>\n",
              "      <td>house</td>\n",
              "      <td>and</td>\n",
              "      <td>studied</td>\n",
              "      <td>the</td>\n",
              "      <td>lighted</td>\n",
              "      <td>square</td>\n",
              "      <td>of</td>\n",
              "      <td>window</td>\n",
              "      <td>:</td>\n",
              "      <td>and</td>\n",
              "      <td>night</td>\n",
              "      <td>after</td>\n",
              "      <td>night</td>\n",
              "      <td>I</td>\n",
              "      <td>had</td>\n",
              "      <td>found</td>\n",
              "      <td>it</td>\n",
              "      <td>lighted</td>\n",
              "      <td>...</td>\n",
              "      <td>,</td>\n",
              "      <td>faintly</td>\n",
              "      <td>and</td>\n",
              "      <td>evenly</td>\n",
              "      <td>.</td>\n",
              "      <td>If</td>\n",
              "      <td>he</td>\n",
              "      <td>was</td>\n",
              "      <td>dead</td>\n",
              "      <td>,</td>\n",
              "      <td>I</td>\n",
              "      <td>thought</td>\n",
              "      <td>,</td>\n",
              "      <td>I</td>\n",
              "      <td>would</td>\n",
              "      <td>see</td>\n",
              "      <td>the</td>\n",
              "      <td>reflection</td>\n",
              "      <td>of</td>\n",
              "      <td>candles</td>\n",
              "      <td>on</td>\n",
              "      <td>the</td>\n",
              "      <td>darkened</td>\n",
              "      <td>blind</td>\n",
              "      <td>for</td>\n",
              "      <td>I</td>\n",
              "      <td>knew</td>\n",
              "      <td>that</td>\n",
              "      <td>two</td>\n",
              "      <td>candles</td>\n",
              "      <td>must</td>\n",
              "      <td>be</td>\n",
              "      <td>set</td>\n",
              "      <td>at</td>\n",
              "      <td>the</td>\n",
              "      <td>head</td>\n",
              "      <td>of</td>\n",
              "      <td>a</td>\n",
              "      <td>corpse</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>stem_p</th>\n",
              "      <td>there</td>\n",
              "      <td>wa</td>\n",
              "      <td>no</td>\n",
              "      <td>hope</td>\n",
              "      <td>for</td>\n",
              "      <td>him</td>\n",
              "      <td>thi</td>\n",
              "      <td>time</td>\n",
              "      <td>:</td>\n",
              "      <td>it</td>\n",
              "      <td>wa</td>\n",
              "      <td>the</td>\n",
              "      <td>third</td>\n",
              "      <td>stroke</td>\n",
              "      <td>.</td>\n",
              "      <td>night</td>\n",
              "      <td>after</td>\n",
              "      <td>night</td>\n",
              "      <td>I</td>\n",
              "      <td>had</td>\n",
              "      <td>pass</td>\n",
              "      <td>the</td>\n",
              "      <td>hous</td>\n",
              "      <td>and</td>\n",
              "      <td>studi</td>\n",
              "      <td>the</td>\n",
              "      <td>light</td>\n",
              "      <td>squar</td>\n",
              "      <td>of</td>\n",
              "      <td>window</td>\n",
              "      <td>:</td>\n",
              "      <td>and</td>\n",
              "      <td>night</td>\n",
              "      <td>after</td>\n",
              "      <td>night</td>\n",
              "      <td>I</td>\n",
              "      <td>had</td>\n",
              "      <td>found</td>\n",
              "      <td>it</td>\n",
              "      <td>light</td>\n",
              "      <td>...</td>\n",
              "      <td>,</td>\n",
              "      <td>faintli</td>\n",
              "      <td>and</td>\n",
              "      <td>evenli</td>\n",
              "      <td>.</td>\n",
              "      <td>If</td>\n",
              "      <td>he</td>\n",
              "      <td>wa</td>\n",
              "      <td>dead</td>\n",
              "      <td>,</td>\n",
              "      <td>I</td>\n",
              "      <td>thought</td>\n",
              "      <td>,</td>\n",
              "      <td>I</td>\n",
              "      <td>would</td>\n",
              "      <td>see</td>\n",
              "      <td>the</td>\n",
              "      <td>reflect</td>\n",
              "      <td>of</td>\n",
              "      <td>candl</td>\n",
              "      <td>on</td>\n",
              "      <td>the</td>\n",
              "      <td>darken</td>\n",
              "      <td>blind</td>\n",
              "      <td>for</td>\n",
              "      <td>I</td>\n",
              "      <td>knew</td>\n",
              "      <td>that</td>\n",
              "      <td>two</td>\n",
              "      <td>candl</td>\n",
              "      <td>must</td>\n",
              "      <td>be</td>\n",
              "      <td>set</td>\n",
              "      <td>at</td>\n",
              "      <td>the</td>\n",
              "      <td>head</td>\n",
              "      <td>of</td>\n",
              "      <td>a</td>\n",
              "      <td>corps</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>stem_l</th>\n",
              "      <td>ther</td>\n",
              "      <td>was</td>\n",
              "      <td>no</td>\n",
              "      <td>hop</td>\n",
              "      <td>for</td>\n",
              "      <td>him</td>\n",
              "      <td>thi</td>\n",
              "      <td>tim</td>\n",
              "      <td>:</td>\n",
              "      <td>it</td>\n",
              "      <td>was</td>\n",
              "      <td>the</td>\n",
              "      <td>third</td>\n",
              "      <td>stroke</td>\n",
              "      <td>.</td>\n",
              "      <td>night</td>\n",
              "      <td>aft</td>\n",
              "      <td>night</td>\n",
              "      <td>i</td>\n",
              "      <td>had</td>\n",
              "      <td>pass</td>\n",
              "      <td>the</td>\n",
              "      <td>hous</td>\n",
              "      <td>and</td>\n",
              "      <td>study</td>\n",
              "      <td>the</td>\n",
              "      <td>light</td>\n",
              "      <td>squ</td>\n",
              "      <td>of</td>\n",
              "      <td>window</td>\n",
              "      <td>:</td>\n",
              "      <td>and</td>\n",
              "      <td>night</td>\n",
              "      <td>aft</td>\n",
              "      <td>night</td>\n",
              "      <td>i</td>\n",
              "      <td>had</td>\n",
              "      <td>found</td>\n",
              "      <td>it</td>\n",
              "      <td>light</td>\n",
              "      <td>...</td>\n",
              "      <td>,</td>\n",
              "      <td>faint</td>\n",
              "      <td>and</td>\n",
              "      <td>ev</td>\n",
              "      <td>.</td>\n",
              "      <td>if</td>\n",
              "      <td>he</td>\n",
              "      <td>was</td>\n",
              "      <td>dead</td>\n",
              "      <td>,</td>\n",
              "      <td>i</td>\n",
              "      <td>thought</td>\n",
              "      <td>,</td>\n",
              "      <td>i</td>\n",
              "      <td>would</td>\n",
              "      <td>see</td>\n",
              "      <td>the</td>\n",
              "      <td>reflect</td>\n",
              "      <td>of</td>\n",
              "      <td>candl</td>\n",
              "      <td>on</td>\n",
              "      <td>the</td>\n",
              "      <td>dark</td>\n",
              "      <td>blind</td>\n",
              "      <td>for</td>\n",
              "      <td>i</td>\n",
              "      <td>knew</td>\n",
              "      <td>that</td>\n",
              "      <td>two</td>\n",
              "      <td>candl</td>\n",
              "      <td>must</td>\n",
              "      <td>be</td>\n",
              "      <td>set</td>\n",
              "      <td>at</td>\n",
              "      <td>the</td>\n",
              "      <td>head</td>\n",
              "      <td>of</td>\n",
              "      <td>a</td>\n",
              "      <td>corps</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lemma</th>\n",
              "      <td>There</td>\n",
              "      <td>wa</td>\n",
              "      <td>no</td>\n",
              "      <td>hope</td>\n",
              "      <td>for</td>\n",
              "      <td>him</td>\n",
              "      <td>this</td>\n",
              "      <td>time</td>\n",
              "      <td>:</td>\n",
              "      <td>it</td>\n",
              "      <td>wa</td>\n",
              "      <td>the</td>\n",
              "      <td>third</td>\n",
              "      <td>stroke</td>\n",
              "      <td>.</td>\n",
              "      <td>Night</td>\n",
              "      <td>after</td>\n",
              "      <td>night</td>\n",
              "      <td>I</td>\n",
              "      <td>had</td>\n",
              "      <td>passed</td>\n",
              "      <td>the</td>\n",
              "      <td>house</td>\n",
              "      <td>and</td>\n",
              "      <td>studied</td>\n",
              "      <td>the</td>\n",
              "      <td>lighted</td>\n",
              "      <td>square</td>\n",
              "      <td>of</td>\n",
              "      <td>window</td>\n",
              "      <td>:</td>\n",
              "      <td>and</td>\n",
              "      <td>night</td>\n",
              "      <td>after</td>\n",
              "      <td>night</td>\n",
              "      <td>I</td>\n",
              "      <td>had</td>\n",
              "      <td>found</td>\n",
              "      <td>it</td>\n",
              "      <td>lighted</td>\n",
              "      <td>...</td>\n",
              "      <td>,</td>\n",
              "      <td>faintly</td>\n",
              "      <td>and</td>\n",
              "      <td>evenly</td>\n",
              "      <td>.</td>\n",
              "      <td>If</td>\n",
              "      <td>he</td>\n",
              "      <td>wa</td>\n",
              "      <td>dead</td>\n",
              "      <td>,</td>\n",
              "      <td>I</td>\n",
              "      <td>thought</td>\n",
              "      <td>,</td>\n",
              "      <td>I</td>\n",
              "      <td>would</td>\n",
              "      <td>see</td>\n",
              "      <td>the</td>\n",
              "      <td>reflection</td>\n",
              "      <td>of</td>\n",
              "      <td>candle</td>\n",
              "      <td>on</td>\n",
              "      <td>the</td>\n",
              "      <td>darkened</td>\n",
              "      <td>blind</td>\n",
              "      <td>for</td>\n",
              "      <td>I</td>\n",
              "      <td>knew</td>\n",
              "      <td>that</td>\n",
              "      <td>two</td>\n",
              "      <td>candle</td>\n",
              "      <td>must</td>\n",
              "      <td>be</td>\n",
              "      <td>set</td>\n",
              "      <td>at</td>\n",
              "      <td>the</td>\n",
              "      <td>head</td>\n",
              "      <td>of</td>\n",
              "      <td>a</td>\n",
              "      <td>corpse</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4 rows × 84 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0    1   2     3    4    5     6   ...  77   78    79  80 81      82 83\n",
              "word    There  was  no  hope  for  him  this  ...  at  the  head  of  a  corpse  .\n",
              "stem_p  there   wa  no  hope  for  him   thi  ...  at  the  head  of  a   corps  .\n",
              "stem_l   ther  was  no   hop  for  him   thi  ...  at  the  head  of  a   corps  .\n",
              "lemma   There   wa  no  hope  for  him  this  ...  at  the  head  of  a  corpse  .\n",
              "\n",
              "[4 rows x 84 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRGsr0Ree-NA"
      },
      "source": [
        "위의 텍스트로 분석한 결과, 일정한 오류 규칙이 보였다. 이 현상이 같은 활용형을 가진 다른 단어들에도 적용되나 확인하기 위해 다음의 워드셋을 가져왔다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdu-oL_BU1OK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "c7a14aed-6081-428a-ce92-783dc70e977d"
      },
      "source": [
        "words=['don\\'t', 'doing', 'have', 'has','going','goes', 'gone', 'went', 'puppies','living','lives', 'fly', 'mainly', 'dies', 'watched', 'starting','policy', 'organization']\n",
        "\n",
        "stm = [s.stem(w) for w in words]\n",
        "lem = [n.lemmatize(w) for w in words]\n",
        "\n",
        "data = [words, stm, lem]\n",
        "\n",
        "df2 = pd.DataFrame(data, index=[\"word\", \"stem\",\"lemma\"])\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>word</th>\n",
              "      <td>don't</td>\n",
              "      <td>doing</td>\n",
              "      <td>have</td>\n",
              "      <td>has</td>\n",
              "      <td>going</td>\n",
              "      <td>goes</td>\n",
              "      <td>gone</td>\n",
              "      <td>went</td>\n",
              "      <td>puppies</td>\n",
              "      <td>living</td>\n",
              "      <td>lives</td>\n",
              "      <td>fly</td>\n",
              "      <td>mainly</td>\n",
              "      <td>dies</td>\n",
              "      <td>watched</td>\n",
              "      <td>starting</td>\n",
              "      <td>policy</td>\n",
              "      <td>organization</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>stem</th>\n",
              "      <td>don't</td>\n",
              "      <td>do</td>\n",
              "      <td>have</td>\n",
              "      <td>ha</td>\n",
              "      <td>go</td>\n",
              "      <td>goe</td>\n",
              "      <td>gone</td>\n",
              "      <td>went</td>\n",
              "      <td>puppi</td>\n",
              "      <td>live</td>\n",
              "      <td>live</td>\n",
              "      <td>fli</td>\n",
              "      <td>mainli</td>\n",
              "      <td>die</td>\n",
              "      <td>watch</td>\n",
              "      <td>start</td>\n",
              "      <td>polici</td>\n",
              "      <td>organ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lemma</th>\n",
              "      <td>don't</td>\n",
              "      <td>doing</td>\n",
              "      <td>have</td>\n",
              "      <td>ha</td>\n",
              "      <td>going</td>\n",
              "      <td>go</td>\n",
              "      <td>gone</td>\n",
              "      <td>went</td>\n",
              "      <td>puppy</td>\n",
              "      <td>living</td>\n",
              "      <td>life</td>\n",
              "      <td>fly</td>\n",
              "      <td>mainly</td>\n",
              "      <td>dy</td>\n",
              "      <td>watched</td>\n",
              "      <td>starting</td>\n",
              "      <td>policy</td>\n",
              "      <td>organization</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0      1     2    3   ...       14        15      16            17\n",
              "word   don't  doing  have  has  ...  watched  starting  policy  organization\n",
              "stem   don't     do  have   ha  ...    watch     start  polici         organ\n",
              "lemma  don't  doing  have   ha  ...  watched  starting  policy  organization\n",
              "\n",
              "[3 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-fvUPtT2M50"
      },
      "source": [
        "## B. Using your system, lemmatize the following words in English.\n",
        "\n",
        "> cats, loves, running, taking, enjoyed, studied,\n",
        "simplest, clever, modest, better, linguistics, teeth,\n",
        "computer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElRmI_5uyZT5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "220eca61-2638-4444-938c-25fd87d9a812"
      },
      "source": [
        "words=\"cats loves running taking enjoyed studied simplest clever modest better \\\n",
        "linguistics teeth computer\"\n",
        "\n",
        "print([s.stem(w) for w in words.split(\" \")])\n",
        "print([n.lemmatize(w) for w in words.split(\" \")]) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['cat', 'love', 'run', 'take', 'enjoy', 'studi', 'simplest', 'clever', 'modest', 'better', 'linguist', 'teeth', 'comput']\n",
            "['cat', 'love', 'running', 'taking', 'enjoyed', 'studied', 'simplest', 'clever', 'modest', 'better', 'linguistics', 'teeth', 'computer']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEBWeHBe2YGy"
      },
      "source": [
        "## C. In your write-up, explain the following. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "062ko2heXbq0"
      },
      "source": [
        "### i. What kinds of error did you find?\n",
        "\n",
        "해당 단어들로 **PorterStemmer**를 이용해본 결과, 다음의 규칙적인 오류가 발견되었다. \n",
        "\n",
        "- s: 동사를 명사라고 판단해, s를 떼어버리는 오류 *ex) was -> wa*\n",
        "- y: 동사나 부사의 끝이 y로 끝나는 경우, 이를 i로 대치 *ex) study -> studi, faintly -> faintli, evenly -> evenli* \n",
        "- e: 명사임에도 불구하고, 마지막의 e를 제거하는 오류 *ex) house, square, corpse*\n",
        "- 명사의 복수형: 복수에서 단수로 되돌리는 과정에서 과잉삭제하는 경우 *ex) candles -> candl*\n",
        "- 동사의 복수형: 복수에서 단수로 되돌리는 과정에서 과소삭제하는 경우 *ex) goes -> goe*\n",
        "\n",
        "해당 단어들로 **WordNetLemmatizer**를 이용해본 결과, 전반적으로 오류가 적었지만 그럼에도 불구하고 다음의 오류가 발견되었다. \n",
        "- s: 동사를 명사라고 판단해, s를 떼어버리는 오류 *ex) was -> wa, has->ha*\n",
        "- 동사의 복수형: 복수에서 단수로 되돌리는 과정에서 과소삭제하는 경우 *ex) goes -> goe*\n",
        "이 외에도, *dies*를 *dy*로 바꾸는 오류가 발생했다. \n",
        "\n",
        "</br>\n",
        "\n",
        "그럼에도 불구하고, 동사의 명사화(ex.-tion) 등의 경우에서는 꽤나 훌륭한 결과를 보였다. \n",
        "\n",
        "### ii. Why such an error happens?\n",
        "\n",
        "앞서 언급했듯, 대부분의 오류는 명사, 동사, 부사 등의 품사를 판별하지 못해 발생했다. \n",
        "그러나 이외에도  lie-lay-lain / lay-laid-laid와 같이 활용 형태는 같지만 본 단어는 다른 경우가 문제가 될 수 있다. \n",
        "\n",
        "이러한 이유 외에도 이들은 규칙 기반으로 이루어져있기 때문에, 좀 더 섬세한 규칙이 필요하다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKqNiKKPU7Z7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "4d8f571e-ab52-4bde-b396-ba75dd05b356"
      },
      "source": [
        "df1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>80</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>word</th>\n",
              "      <td>There</td>\n",
              "      <td>was</td>\n",
              "      <td>no</td>\n",
              "      <td>hope</td>\n",
              "      <td>for</td>\n",
              "      <td>him</td>\n",
              "      <td>this</td>\n",
              "      <td>time</td>\n",
              "      <td>:</td>\n",
              "      <td>it</td>\n",
              "      <td>was</td>\n",
              "      <td>the</td>\n",
              "      <td>third</td>\n",
              "      <td>stroke</td>\n",
              "      <td>.</td>\n",
              "      <td>Night</td>\n",
              "      <td>after</td>\n",
              "      <td>night</td>\n",
              "      <td>I</td>\n",
              "      <td>had</td>\n",
              "      <td>passed</td>\n",
              "      <td>the</td>\n",
              "      <td>house</td>\n",
              "      <td>and</td>\n",
              "      <td>studied</td>\n",
              "      <td>the</td>\n",
              "      <td>lighted</td>\n",
              "      <td>square</td>\n",
              "      <td>of</td>\n",
              "      <td>window</td>\n",
              "      <td>:</td>\n",
              "      <td>and</td>\n",
              "      <td>night</td>\n",
              "      <td>after</td>\n",
              "      <td>night</td>\n",
              "      <td>I</td>\n",
              "      <td>had</td>\n",
              "      <td>found</td>\n",
              "      <td>it</td>\n",
              "      <td>lighted</td>\n",
              "      <td>...</td>\n",
              "      <td>,</td>\n",
              "      <td>faintly</td>\n",
              "      <td>and</td>\n",
              "      <td>evenly</td>\n",
              "      <td>.</td>\n",
              "      <td>If</td>\n",
              "      <td>he</td>\n",
              "      <td>was</td>\n",
              "      <td>dead</td>\n",
              "      <td>,</td>\n",
              "      <td>I</td>\n",
              "      <td>thought</td>\n",
              "      <td>,</td>\n",
              "      <td>I</td>\n",
              "      <td>would</td>\n",
              "      <td>see</td>\n",
              "      <td>the</td>\n",
              "      <td>reflection</td>\n",
              "      <td>of</td>\n",
              "      <td>candles</td>\n",
              "      <td>on</td>\n",
              "      <td>the</td>\n",
              "      <td>darkened</td>\n",
              "      <td>blind</td>\n",
              "      <td>for</td>\n",
              "      <td>I</td>\n",
              "      <td>knew</td>\n",
              "      <td>that</td>\n",
              "      <td>two</td>\n",
              "      <td>candles</td>\n",
              "      <td>must</td>\n",
              "      <td>be</td>\n",
              "      <td>set</td>\n",
              "      <td>at</td>\n",
              "      <td>the</td>\n",
              "      <td>head</td>\n",
              "      <td>of</td>\n",
              "      <td>a</td>\n",
              "      <td>corpse</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>stem_p</th>\n",
              "      <td>there</td>\n",
              "      <td>wa</td>\n",
              "      <td>no</td>\n",
              "      <td>hope</td>\n",
              "      <td>for</td>\n",
              "      <td>him</td>\n",
              "      <td>thi</td>\n",
              "      <td>time</td>\n",
              "      <td>:</td>\n",
              "      <td>it</td>\n",
              "      <td>wa</td>\n",
              "      <td>the</td>\n",
              "      <td>third</td>\n",
              "      <td>stroke</td>\n",
              "      <td>.</td>\n",
              "      <td>night</td>\n",
              "      <td>after</td>\n",
              "      <td>night</td>\n",
              "      <td>I</td>\n",
              "      <td>had</td>\n",
              "      <td>pass</td>\n",
              "      <td>the</td>\n",
              "      <td>hous</td>\n",
              "      <td>and</td>\n",
              "      <td>studi</td>\n",
              "      <td>the</td>\n",
              "      <td>light</td>\n",
              "      <td>squar</td>\n",
              "      <td>of</td>\n",
              "      <td>window</td>\n",
              "      <td>:</td>\n",
              "      <td>and</td>\n",
              "      <td>night</td>\n",
              "      <td>after</td>\n",
              "      <td>night</td>\n",
              "      <td>I</td>\n",
              "      <td>had</td>\n",
              "      <td>found</td>\n",
              "      <td>it</td>\n",
              "      <td>light</td>\n",
              "      <td>...</td>\n",
              "      <td>,</td>\n",
              "      <td>faintli</td>\n",
              "      <td>and</td>\n",
              "      <td>evenli</td>\n",
              "      <td>.</td>\n",
              "      <td>If</td>\n",
              "      <td>he</td>\n",
              "      <td>wa</td>\n",
              "      <td>dead</td>\n",
              "      <td>,</td>\n",
              "      <td>I</td>\n",
              "      <td>thought</td>\n",
              "      <td>,</td>\n",
              "      <td>I</td>\n",
              "      <td>would</td>\n",
              "      <td>see</td>\n",
              "      <td>the</td>\n",
              "      <td>reflect</td>\n",
              "      <td>of</td>\n",
              "      <td>candl</td>\n",
              "      <td>on</td>\n",
              "      <td>the</td>\n",
              "      <td>darken</td>\n",
              "      <td>blind</td>\n",
              "      <td>for</td>\n",
              "      <td>I</td>\n",
              "      <td>knew</td>\n",
              "      <td>that</td>\n",
              "      <td>two</td>\n",
              "      <td>candl</td>\n",
              "      <td>must</td>\n",
              "      <td>be</td>\n",
              "      <td>set</td>\n",
              "      <td>at</td>\n",
              "      <td>the</td>\n",
              "      <td>head</td>\n",
              "      <td>of</td>\n",
              "      <td>a</td>\n",
              "      <td>corps</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>stem_l</th>\n",
              "      <td>ther</td>\n",
              "      <td>was</td>\n",
              "      <td>no</td>\n",
              "      <td>hop</td>\n",
              "      <td>for</td>\n",
              "      <td>him</td>\n",
              "      <td>thi</td>\n",
              "      <td>tim</td>\n",
              "      <td>:</td>\n",
              "      <td>it</td>\n",
              "      <td>was</td>\n",
              "      <td>the</td>\n",
              "      <td>third</td>\n",
              "      <td>stroke</td>\n",
              "      <td>.</td>\n",
              "      <td>night</td>\n",
              "      <td>aft</td>\n",
              "      <td>night</td>\n",
              "      <td>i</td>\n",
              "      <td>had</td>\n",
              "      <td>pass</td>\n",
              "      <td>the</td>\n",
              "      <td>hous</td>\n",
              "      <td>and</td>\n",
              "      <td>study</td>\n",
              "      <td>the</td>\n",
              "      <td>light</td>\n",
              "      <td>squ</td>\n",
              "      <td>of</td>\n",
              "      <td>window</td>\n",
              "      <td>:</td>\n",
              "      <td>and</td>\n",
              "      <td>night</td>\n",
              "      <td>aft</td>\n",
              "      <td>night</td>\n",
              "      <td>i</td>\n",
              "      <td>had</td>\n",
              "      <td>found</td>\n",
              "      <td>it</td>\n",
              "      <td>light</td>\n",
              "      <td>...</td>\n",
              "      <td>,</td>\n",
              "      <td>faint</td>\n",
              "      <td>and</td>\n",
              "      <td>ev</td>\n",
              "      <td>.</td>\n",
              "      <td>if</td>\n",
              "      <td>he</td>\n",
              "      <td>was</td>\n",
              "      <td>dead</td>\n",
              "      <td>,</td>\n",
              "      <td>i</td>\n",
              "      <td>thought</td>\n",
              "      <td>,</td>\n",
              "      <td>i</td>\n",
              "      <td>would</td>\n",
              "      <td>see</td>\n",
              "      <td>the</td>\n",
              "      <td>reflect</td>\n",
              "      <td>of</td>\n",
              "      <td>candl</td>\n",
              "      <td>on</td>\n",
              "      <td>the</td>\n",
              "      <td>dark</td>\n",
              "      <td>blind</td>\n",
              "      <td>for</td>\n",
              "      <td>i</td>\n",
              "      <td>knew</td>\n",
              "      <td>that</td>\n",
              "      <td>two</td>\n",
              "      <td>candl</td>\n",
              "      <td>must</td>\n",
              "      <td>be</td>\n",
              "      <td>set</td>\n",
              "      <td>at</td>\n",
              "      <td>the</td>\n",
              "      <td>head</td>\n",
              "      <td>of</td>\n",
              "      <td>a</td>\n",
              "      <td>corps</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lemma</th>\n",
              "      <td>There</td>\n",
              "      <td>wa</td>\n",
              "      <td>no</td>\n",
              "      <td>hope</td>\n",
              "      <td>for</td>\n",
              "      <td>him</td>\n",
              "      <td>this</td>\n",
              "      <td>time</td>\n",
              "      <td>:</td>\n",
              "      <td>it</td>\n",
              "      <td>wa</td>\n",
              "      <td>the</td>\n",
              "      <td>third</td>\n",
              "      <td>stroke</td>\n",
              "      <td>.</td>\n",
              "      <td>Night</td>\n",
              "      <td>after</td>\n",
              "      <td>night</td>\n",
              "      <td>I</td>\n",
              "      <td>had</td>\n",
              "      <td>passed</td>\n",
              "      <td>the</td>\n",
              "      <td>house</td>\n",
              "      <td>and</td>\n",
              "      <td>studied</td>\n",
              "      <td>the</td>\n",
              "      <td>lighted</td>\n",
              "      <td>square</td>\n",
              "      <td>of</td>\n",
              "      <td>window</td>\n",
              "      <td>:</td>\n",
              "      <td>and</td>\n",
              "      <td>night</td>\n",
              "      <td>after</td>\n",
              "      <td>night</td>\n",
              "      <td>I</td>\n",
              "      <td>had</td>\n",
              "      <td>found</td>\n",
              "      <td>it</td>\n",
              "      <td>lighted</td>\n",
              "      <td>...</td>\n",
              "      <td>,</td>\n",
              "      <td>faintly</td>\n",
              "      <td>and</td>\n",
              "      <td>evenly</td>\n",
              "      <td>.</td>\n",
              "      <td>If</td>\n",
              "      <td>he</td>\n",
              "      <td>wa</td>\n",
              "      <td>dead</td>\n",
              "      <td>,</td>\n",
              "      <td>I</td>\n",
              "      <td>thought</td>\n",
              "      <td>,</td>\n",
              "      <td>I</td>\n",
              "      <td>would</td>\n",
              "      <td>see</td>\n",
              "      <td>the</td>\n",
              "      <td>reflection</td>\n",
              "      <td>of</td>\n",
              "      <td>candle</td>\n",
              "      <td>on</td>\n",
              "      <td>the</td>\n",
              "      <td>darkened</td>\n",
              "      <td>blind</td>\n",
              "      <td>for</td>\n",
              "      <td>I</td>\n",
              "      <td>knew</td>\n",
              "      <td>that</td>\n",
              "      <td>two</td>\n",
              "      <td>candle</td>\n",
              "      <td>must</td>\n",
              "      <td>be</td>\n",
              "      <td>set</td>\n",
              "      <td>at</td>\n",
              "      <td>the</td>\n",
              "      <td>head</td>\n",
              "      <td>of</td>\n",
              "      <td>a</td>\n",
              "      <td>corpse</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4 rows × 84 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0    1   2     3    4    5     6   ...  77   78    79  80 81      82 83\n",
              "word    There  was  no  hope  for  him  this  ...  at  the  head  of  a  corpse  .\n",
              "stem_p  there   wa  no  hope  for  him   thi  ...  at  the  head  of  a   corps  .\n",
              "stem_l   ther  was  no   hop  for  him   thi  ...  at  the  head  of  a   corps  .\n",
              "lemma   There   wa  no  hope  for  him  this  ...  at  the  head  of  a  corpse  .\n",
              "\n",
              "[4 rows x 84 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTFNo-1qYqZG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "71e762f1-30b5-4426-c85f-2eebbb0c35f3"
      },
      "source": [
        "df2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>word</th>\n",
              "      <td>don't</td>\n",
              "      <td>doing</td>\n",
              "      <td>have</td>\n",
              "      <td>has</td>\n",
              "      <td>going</td>\n",
              "      <td>goes</td>\n",
              "      <td>gone</td>\n",
              "      <td>went</td>\n",
              "      <td>puppies</td>\n",
              "      <td>living</td>\n",
              "      <td>lives</td>\n",
              "      <td>fly</td>\n",
              "      <td>mainly</td>\n",
              "      <td>dies</td>\n",
              "      <td>watched</td>\n",
              "      <td>starting</td>\n",
              "      <td>policy</td>\n",
              "      <td>organization</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>stem</th>\n",
              "      <td>don't</td>\n",
              "      <td>do</td>\n",
              "      <td>have</td>\n",
              "      <td>ha</td>\n",
              "      <td>go</td>\n",
              "      <td>goe</td>\n",
              "      <td>gone</td>\n",
              "      <td>went</td>\n",
              "      <td>puppi</td>\n",
              "      <td>live</td>\n",
              "      <td>live</td>\n",
              "      <td>fli</td>\n",
              "      <td>mainli</td>\n",
              "      <td>die</td>\n",
              "      <td>watch</td>\n",
              "      <td>start</td>\n",
              "      <td>polici</td>\n",
              "      <td>organ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lemma</th>\n",
              "      <td>don't</td>\n",
              "      <td>doing</td>\n",
              "      <td>have</td>\n",
              "      <td>ha</td>\n",
              "      <td>going</td>\n",
              "      <td>go</td>\n",
              "      <td>gone</td>\n",
              "      <td>went</td>\n",
              "      <td>puppy</td>\n",
              "      <td>living</td>\n",
              "      <td>life</td>\n",
              "      <td>fly</td>\n",
              "      <td>mainly</td>\n",
              "      <td>dy</td>\n",
              "      <td>watched</td>\n",
              "      <td>starting</td>\n",
              "      <td>policy</td>\n",
              "      <td>organization</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0      1     2    3   ...       14        15      16            17\n",
              "word   don't  doing  have  has  ...  watched  starting  policy  organization\n",
              "stem   don't     do  have   ha  ...    watch     start  polici         organ\n",
              "lemma  don't  doing  have   ha  ...  watched  starting  policy  organization\n",
              "\n",
              "[3 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OADut4CYZDO"
      },
      "source": [
        "### iii. Which linguistic features should be added into the system for better performance?\n",
        "\n",
        "위에서 언급했듯, 일차적으로는 품사정보를 넘겨주어 성능을 향상할 수 있다. 실제로, WordNetLemmatizer에 품사정보를 넘겨주면 훨씬 좋은 성능을 보이는 것을 확인할 수 있다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqxlsZanzH7M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c40962f0-9156-4d61-c02f-e20fafb10fa5"
      },
      "source": [
        "n.lemmatize('does')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'doe'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lixTDXqd1loU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3718daf9-71bb-4dd0-a218-482d0d197d25"
      },
      "source": [
        "n.lemmatize('does', 'v')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'do'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QL4FcwMmcxLe"
      },
      "source": [
        "또 다르게는 문장의 맥락 정보를 넘겨줄 수 있다. 하지만 이는 단순히 하나의 단어를 보는 것이 아닌 훨씬 큰 차원의 문제이다. 따라서, wordnet을 이용해 좀 더 구체적인 word sense를 넘겨주는 것이 해결책이 될 수 있을 것이다. \n",
        "\n"
      ]
    }
  ]
}