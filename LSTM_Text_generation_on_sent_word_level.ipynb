{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "LSTM Text generation on sent-word-level.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rn49iOr0lKG9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "547d14cf-5535-4c72-929d-551b3879765f"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "import unicodedata\n",
        "import random\n",
        "import re\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRnQyhhblKHB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b81dbfde-e5cf-4a9a-cd41-2705b421fc52"
      },
      "source": [
        "# Check if GPU is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "if(train_on_gpu):\n",
        "    print('Training on GPU!')\n",
        "else: \n",
        "    print('No GPU available, training on CPU')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on GPU!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1Jhp43wlKHD"
      },
      "source": [
        "# 몇 개의 단어를 context vec으로 사용할지 설정\n",
        "\n",
        "context_num = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmYtc7HRlKHG"
      },
      "source": [
        "lines = open(\"/content/textbook\", \"r\").read().split('\\n')\n",
        "# lines = lines[:1000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyP4nYcylKHI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8bdbc42-2f82-42dc-9d6f-a18e13aaa050"
      },
      "source": [
        "test_sentence = [word_tokenize(s) for s in lines]\n",
        "print(test_sentence[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['sara', ':', 'my', 'name', 'is', 'sara', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyk4HBSzlKHK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3229a84-9959-478c-9d0f-df09b0e386a5"
      },
      "source": [
        "vocab = []\n",
        "for sent in test_sentence:\n",
        "    for word in sent: vocab.append(word)\n",
        "        \n",
        "vocab = set(vocab)\n",
        "voc_len=len(vocab)\n",
        "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
        "\n",
        "print(voc_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1552\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TmSr9DrlKHN"
      },
      "source": [
        "MAX_LEN = 75"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBeEhvohlKHQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "5a949ca9-db16-42ee-f5f1-4659d0675413"
      },
      "source": [
        "input_ids = []\n",
        "for sent in test_sentence:\n",
        "    input_ids.append([word_to_ix[w] for w in sent])\n",
        "\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "print(input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1005  657  652  486  697 1209  980 1520 1187    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6I3HYeI-lKHS"
      },
      "source": [
        "inp = []\n",
        "tar = []\n",
        "\n",
        "for sentence in input_ids:\n",
        "    for i in range(len(sentence)-context_num):\n",
        "        context = sentence[i:i+context_num]\n",
        "        target = sentence[i+context_num]\n",
        "        if sum(context.tolist())+target==0: continue\n",
        "        inp.append(context)\n",
        "        tar.append(torch.tensor([target]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTD1PSVplKHW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0a6e2e5a-b3aa-4e2a-d06e-4c487d222afa"
      },
      "source": [
        "inp = torch.tensor(inp)\n",
        "data_len = len(inp)\n",
        "print(data_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2205126\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66nOj1eelKHY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f2c4d382-69ba-4e20-a4cc-6415a49f5716"
      },
      "source": [
        "for i, t in zip(inp, tar):\n",
        "    print(i.size())\n",
        "    print(i)\n",
        "    print(t)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4])\n",
            "tensor([1005,  657,  652,  486])\n",
            "tensor([697])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InyxmHmNlKHa"
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size*context_num, hidden_size, n_layers,batch_first=True,\n",
        "                          bidirectional=False)\n",
        "        self.decoder = nn.Linear(hidden_size, output_size)\n",
        "    \n",
        "    def forward(self, input, hc):\n",
        "        input = self.encoder(input.view(1, -1))\n",
        "        output, (hidden, context) = self.lstm(input.view(1, 1, -1), hc)        \n",
        "        output = self.decoder(output.view(1, -1))        \n",
        "        return output, hidden, context\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return Variable((torch.zeros(self.n_layers, 1, self.hidden_size)))\n",
        "    \n",
        "    def init_context(self):\n",
        "        return Variable((torch.zeros(self.n_layers, 1, self.hidden_size)))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjigerNblKHc"
      },
      "source": [
        "import time, math\n",
        "\n",
        "def time_since(since):\n",
        "    s = time.time() - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STQs0ldhlKHf"
      },
      "source": [
        "def train(inp, target):\n",
        "    decoder.zero_grad()\n",
        "    hidden = decoder.init_hidden().cuda()\n",
        "    context = decoder.init_context().cuda()\n",
        "    loss = 0\n",
        "    output, hidden, context = decoder(inp.cuda(), (hidden, context))\n",
        "    \n",
        "    loss += criterion(output, target.cuda())\n",
        "    loss.backward()\n",
        "    decoder_optimizer.step()\n",
        "    \n",
        "    return loss.data.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BltyA0kGlKHq"
      },
      "source": [
        "def generate(prime_str='the name of the dog', predict_len=75, temperature=0.8):\n",
        "    torch.no_grad()\n",
        "\n",
        "    hidden = decoder.init_hidden().cuda()\n",
        "    context = decoder.init_context().cuda()\n",
        "    hc = (hidden, context)\n",
        "\n",
        "    for p in range(predict_len):\n",
        "        prime_input = torch.tensor([word_to_ix[w] for w in prime_str.split()], dtype=torch.long).cuda()\n",
        "        inp = prime_input[-1*context_num:]\n",
        "\n",
        "        if torch.sum(inp) == 0: break  # 종료 조건\n",
        "            \n",
        "        output, hidden, context = decoder(inp, hc)\n",
        "        \n",
        "        # Sample from the network as a multinomial distribution\n",
        "        output_dist = F.softmax(output.data).view(-1).div(temperature).exp()\n",
        "        \n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\n",
        "    \n",
        "        \n",
        "        # Add predicted word to string and use as next input\n",
        "        predicted_word = list(word_to_ix.keys())[list(word_to_ix.values()).index(top_i)]\n",
        "        prime_str += \" \" + predicted_word\n",
        "\n",
        "    return prime_str"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Mux1Hp1lKHi"
      },
      "source": [
        "n_epochs = 10\n",
        "print_every = 2\n",
        "plot_every = 2\n",
        "hidden_size = 100\n",
        "n_layers = 2\n",
        "lr = 0.015\n",
        "\n",
        "decoder = LSTM(voc_len, hidden_size, voc_len, n_layers)\n",
        "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "decoder.train()\n",
        "\n",
        "start = time.time()\n",
        "all_losses = []\n",
        "decoder.cuda()\n",
        "\n",
        "\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    print(\"Epoch: \", epoch)\n",
        "    loss_avg = 0\n",
        "    for i,t in zip(inp, tar):\n",
        "        loss = train(i,t)       \n",
        "        loss_avg += loss\n",
        "\n",
        "    if epoch % print_every == 0:\n",
        "        print('[%s (%d %d%%)]' % (time_since(start), epoch, epoch / n_epochs * 100))\n",
        "        print(generate())\n",
        "\n",
        "    if epoch % plot_every == 0:\n",
        "        all_losses.append((loss_avg/data_len)/ plot_every)\n",
        "        loss_avg = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HROAicng9J7w"
      },
      "source": [
        "all_losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pn4jP9_Tb1t3"
      },
      "source": [
        "torch.save(decoder, 'lstmmodel.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4wf5uO3lKHq"
      },
      "source": [
        "## Generate sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqZoDA0hlKHs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "835315d9-73ad-42a0-945d-d15dc05580dc"
      },
      "source": [
        "print(generate('the name of the dog', 75, temperature=3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "the name of the dog by dogs shooting ! last computer tteok know comes flowers rocket great reading sound visit birds third don'y let waht angry than juho 22nd teach fred made isstv they floor rode 205 everything mon mine jack sure enjoy $ letters snowing ketchup beethoven painting roe hit bees last watch favorite echo loves lost number three tired sons t-shirts song sit hercules whoose dog anu sweet thursday librarian borte daddy watched will mrs.lee magic swimming quizmaster club l ? viking noodles tuesday . thousand rockets ... every salty 11:00 dad rock history watching bongsu gyeongsang-do house ideas studying annika takes stopped\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5pxUnlLlKHu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzT7fU4ZlKHx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}