{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "GRU Text generation on sent-word-level.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIeigVZ2lMr3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "8ccadd81-6cc3-4f55-c0df-b89987880fa3"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "import unicodedata\n",
        "import random\n",
        "import re\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6mnYSOVlMr6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3894e4d5-2e99-4b45-c1b7-45b0f3037da8"
      },
      "source": [
        "# Check if GPU is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "if(train_on_gpu):\n",
        "    print('Training on GPU!')\n",
        "else: \n",
        "    print('No GPU available, training on CPU; consider making n_epochs very small.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on GPU!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qj6GAjRYlMr8"
      },
      "source": [
        "# 몇 개의 단어를 context vec으로 사용할지 설정\n",
        "\n",
        "context_num = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLV7QAMTlMr_"
      },
      "source": [
        "lines = open(\"/content/textbook\", \"r\").read().split('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vg8sJp8QbTkQ"
      },
      "source": [
        "test_sentence = [word_tokenize(s) for s in lines]\n",
        "print(test_sentence[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHdADtrLlMsE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c333f33-e8dd-4a7f-e236-563fe1faa173"
      },
      "source": [
        "vocab = []\n",
        "for sent in test_sentence:\n",
        "    for word in sent: vocab.append(word)\n",
        "        \n",
        "vocab = set(vocab)\n",
        "voc_len=len(vocab)\n",
        "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
        "\n",
        "print(voc_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1552\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjenPtmElMsH"
      },
      "source": [
        "MAX_LEN = 75"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBsMWDE3lMsK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "3316fa79-556d-402e-aac2-b150041e17f0"
      },
      "source": [
        "input_ids = []\n",
        "for sent in test_sentence:\n",
        "    input_ids.append([word_to_ix[w] for w in sent])\n",
        "\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "print(input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1243   56 1323  699  570  219  300  345  838    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCGrwBG1lMsM"
      },
      "source": [
        "inp = []\n",
        "tar = []\n",
        "\n",
        "for sentence in input_ids:\n",
        "    for i in range(len(sentence)-context_num):\n",
        "        context = sentence[i:i+context_num]\n",
        "        target = sentence[i+context_num]\n",
        "        if sum(context.tolist())+target==0: continue\n",
        "        inp.append(context)\n",
        "        tar.append(torch.tensor([target]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeXntzonlMsO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c47ca612-38b5-462d-dfc8-3acbde46d20e"
      },
      "source": [
        "inp = torch.tensor(inp)\n",
        "data_len = len(inp)\n",
        "print(data_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2205126\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNFunnyGlMsR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b17e3715-1bf1-4da8-d976-07779eca75fa"
      },
      "source": [
        "for i, t in zip(inp, tar):\n",
        "    print(i.size())\n",
        "    print(i)\n",
        "    print(t)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4])\n",
            "tensor([1243,   56, 1323,  699])\n",
            "tensor([570])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEDVDws9lMsU"
      },
      "source": [
        "class GRU(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
        "        super(RNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size*context_num, hidden_size, n_layers,batch_first=True,\n",
        "                          bidirectional=False)\n",
        "        self.decoder = nn.Linear(hidden_size, output_size)\n",
        "    \n",
        "    def forward(self, input, hidden):\n",
        "        input = self.encoder(input.view(1, -1))\n",
        "        output, hidden = self.gru(input.view(1, 1, -1), hidden)\n",
        "        output = self.decoder(output.view(1, -1))\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JNVhE4plMsW"
      },
      "source": [
        "import time, math\n",
        "\n",
        "def time_since(since):\n",
        "    s = time.time() - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL9oyMjUlMsZ"
      },
      "source": [
        "def train(inp, target):\n",
        "    hidden = decoder.init_hidden().cuda()\n",
        "    loss = 0\n",
        "    decoder.zero_grad()\n",
        "\n",
        "    output, hidden = decoder(inp.cuda(), hidden) \n",
        "    \n",
        "    loss += criterion(output, target.cuda())\n",
        "    loss.backward()\n",
        "    decoder_optimizer.step()\n",
        "    \n",
        "    return loss.data.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WX4GNvVlMsg"
      },
      "source": [
        "def generate(prime_str='the name of the dog', predict_len=175, temperature=0.8):\n",
        "    torch.no_grad()\n",
        "    hidden = decoder.init_hidden().cuda()\n",
        "\n",
        "    for p in range(predict_len):\n",
        "        prime_input = torch.tensor([word_to_ix[w] for w in prime_str.split()], dtype=torch.long).cuda()\n",
        "        inp = prime_input[-1*context_num:] \n",
        "\n",
        "        if torch.sum(inp) == 0: break  # 종료 조건\n",
        "            \n",
        "        output, hidden = decoder(inp, hidden)\n",
        "        \n",
        "        # Sample from the network as a multinomial distribution\n",
        "        output_dist = F.softmax(output.data).view(-1).div(temperature).exp()\n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\n",
        "    \n",
        "        \n",
        "        # Add predicted word to string and use as next input\n",
        "        predicted_word = list(word_to_ix.keys())[list(word_to_ix.values()).index(top_i)]\n",
        "        prime_str += \" \" + predicted_word\n",
        "\n",
        "    return prime_str"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fySA5xzAlMsb"
      },
      "source": [
        "n_epochs = 10\n",
        "print_every = 2\n",
        "plot_every = 2\n",
        "hidden_size = 100\n",
        "n_layers = 2\n",
        "lr = 0.015\n",
        "\n",
        "decoder = GRU(voc_len, hidden_size, voc_len, n_layers)\n",
        "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "decoder.train()\n",
        "decoder.cuda()\n",
        "\n",
        "start = time.time()\n",
        "all_losses = []\n",
        "\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    print(\"Epoch: \", epoch)\n",
        "    loss_avg = 0\n",
        "    for i,t in zip(inp, tar):\n",
        "        loss = train(i,t)       \n",
        "        loss_avg += loss\n",
        "\n",
        "    if epoch % print_every == 0:\n",
        "        print('[%s (%d %d%%)]' % (time_since(start), epoch, epoch / n_epochs * 100))\n",
        "        print(generate())\n",
        "\n",
        "    if epoch % plot_every == 0:\n",
        "        all_losses.append((loss_avg/data_len) / plot_every)\n",
        "        loss_avg = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2g1mihUbbEi"
      },
      "source": [
        "torch.save(decoder, 'grumodel.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjhLqaHZlMsf"
      },
      "source": [
        "## Generate sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR9uugpolMsj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "a676567a-e1ca-483a-d6bc-025d12c5eaaa"
      },
      "source": [
        "print(generate('the name of the dog is', 75, temperature=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "the name of the dog is choe paintings supermarket eating ella jim ha moves ketchup 160 looked matter him gim glasses sour yu chris lot raise rain selina too anything ice here take hikers excellent hamburgers 3,000 bees africa so p.e t5 reporter used now learning floor ant 5th program dasom ... once tired skating father quiz happychildren willy isstv kiwis grandma kangaroo baby stars happychildren hooray market yuna semi traveler cakes sunny andong gim date would very course hand cooking boring calling asia yourself having arm earth job rain flowers gomawoyo ahh b-e-n loved foot stories 23rd no brothers talking borte fever beacause teach gim medicine small eat gang line health design more sleeping mr.allan blind plane right faster scissors 15th shopkeeper elephant move kajuru lke up lion picures helen pants ha.ben andy brothers save suah front places ray ... see miso writing expensive ahh done anu again does finger cook ? pierre juho ladybug 30 officer tanay usually 25th ivan weekends julia march dreaming kyle plant rode brush office august dogs hongdo clean legs vegetable chair fought red pants m-i-s-o change rockets shooting brazil okay.juho banks festival dancing august visit 13:00-15:00. paper cheap programs practice times here bed arm fall korean ming kelly myeongdong skating meet sally can meet soccer danny lucky fish book opening grapes t-ball tuho dad h-a-n sleeping mine lee miss lives runny wore rabbit slow desks chess jerry panda indian floor jason goo full taller sixth lots names coming think are miss problem 40 chef alice small borte birds 're bedroom again flags girl2 cup lucky whew camels mountain son2 band wrong server sell four longer higher chen bathroom hurt break shows jinu card woman picture sounds son3 kebab 110 helps glasses math hanok annika hanok brothers hello & box too wanted achoo sejong tooth jane bad alice dancer sour 5,000 busan what spicy line tv table by goodbye man lady story turkish stopped poor g1 20 quiz miso window loves boy mr. feet aha snowing chemseongdae mr.brown skate yi once china flags old u.s. baseball palying tommy king glue horse jason moving kelly ha book b-e-n. swim 13:00-15:00. sorry piano ms.allan make contest broke cows warm took pants bulguksa games 10,000 star nick both ruuners kakuru ostriches face merchant l.a vietnamese gyengju there j-a-s-o-n lessons judy sees in dog tree lice talking difficult smater fans hangeul manet catch opening glasses sars 6 mom turere happychildren emial e-mail cap playground\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6NclaIWlMsl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXmZ_7hdlMsn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}